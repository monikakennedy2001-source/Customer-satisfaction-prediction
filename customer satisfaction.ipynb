{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "425f0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77b06b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']\n",
      "Gender: ['Male' 'Female']\n",
      "Customer Type: ['Loyal Customer' 'disloyal Customer']\n",
      "Type of Travel: ['Personal Travel' 'Business travel']\n",
      "Class: ['Eco Plus' 'Business' 'Eco']\n",
      "satisfaction: ['neutral or dissatisfied' 'satisfied']\n",
      "Index(['Gender', 'Customer Type', 'Age', 'Type of Travel', 'Flight Distance',\n",
      "       'Inflight wifi service', 'Departure/Arrival time convenient',\n",
      "       'Ease of Online booking', 'Gate location', 'Food and drink',\n",
      "       'Online boarding', 'Seat comfort', 'Inflight entertainment',\n",
      "       'On-board service', 'Leg room service', 'Baggage handling',\n",
      "       'Checkin service', 'Inflight service', 'Cleanliness',\n",
      "       'Departure Delay in Minutes', 'Arrival Delay in Minutes',\n",
      "       'satisfaction', 'Class_Business', 'Class_Eco', 'Class_Eco Plus',\n",
      "       'satisfaction_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load the dataset\n",
    "df = pd.read_csv(\"Passenger_satisfaction.csv\")\n",
    "\n",
    "# 2. Drop duplicates early\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 3. Fill missing values\n",
    "df['Arrival Delay in Minutes'].fillna(df['Arrival Delay in Minutes'].median(), inplace=True)\n",
    "\n",
    "# 4. Drop unwanted columns\n",
    "df.drop(columns=['Unnamed: 0', 'id'], inplace=True, errors='ignore')\n",
    "\n",
    "# 5. Inspect categorical columns\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "print(\"Categorical Columns:\", categorical_cols)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n",
    "\n",
    "# 6. Label encode binary categorical columns\n",
    "label_encoders = {}\n",
    "binary_cols = ['Gender', 'Customer Type', 'Type of Travel']  # ✅ Removed 'Class'\n",
    "\n",
    "for col in binary_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 7. One-hot encode 'Class'\n",
    "df = pd.get_dummies(df, columns=['Class'])  # ✅ No error here\n",
    "\n",
    "# 8. Encode target variable\n",
    "le_target = LabelEncoder()\n",
    "df['satisfaction_encoded'] = le_target.fit_transform(df['satisfaction'])\n",
    "\n",
    "# Optional: Check the final columns\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7854b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Rating features\n",
    "rating_features = [\n",
    "    'Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "    'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "    'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "    'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness'\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c891fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18,5))\n",
    "\n",
    "sns.histplot(df['Age'], bins=30, ax=axes[0], kde=True)\n",
    "axes[0].set_title('Age Distribution')\n",
    "\n",
    "sns.histplot(df['Flight Distance'], bins=30, ax=axes[1], kde=True)\n",
    "axes[1].set_title('Flight Distance Distribution')\n",
    "\n",
    "sns.histplot(df['Arrival Delay in Minutes'], bins=30, ax=axes[2], kde=True)\n",
    "axes[2].set_title('Arrival Delay Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"eda_distribution_plots.png\")  # Save the figure\n",
    "plt.close()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "756458c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Categorical plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.countplot(x='Gender', hue='satisfaction', data=df, ax=axes[0])\n",
    "axes[0].set_title('Satisfaction by Gender')\n",
    "\n",
    "sns.countplot(x='Customer Type', hue='satisfaction', data=df, ax=axes[1])\n",
    "axes[1].set_title('Satisfaction by Customer Type')\n",
    "\n",
    "sns.countplot(x='Type of Travel', hue='satisfaction', data=df, ax=axes[2])\n",
    "axes[2].set_title('Satisfaction by Type of Travel')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('categorical_satisfaction.png')\n",
    "plt.close()\n",
    "\n",
    "# Define numeric rating features\n",
    "rating_features = [\n",
    "    'Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "    'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "    'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "    'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness'\n",
    "]\n",
    "\n",
    "# Numeric columns to consider for correlation heatmap (only numeric)\n",
    "numeric_cols = ['Age', 'Flight Distance'] + [col for col in rating_features if col in df.columns]\n",
    "\n",
    "# Ensure 'satisfaction_encoded' is in your dataframe and numeric (0/1)\n",
    "if 'satisfaction_encoded' not in df.columns:\n",
    "    # Example encoding: \n",
    "    df['satisfaction_encoded'] = df['satisfaction'].map({'satisfied': 1, 'neutral or dissatisfied': 0})\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr = df[numeric_cols + ['satisfaction_encoded']].corr()\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Numeric Features and Satisfaction')\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d62a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define important features based on your feature importance & correlation\n",
    "important_features = [\n",
    "    'Online boarding', 'Inflight wifi service', 'Type of Travel',\n",
    "    'Class_Business', 'Inflight entertainment', 'Flight Distance',\n",
    "    'Ease of Online booking', 'Age', 'Customer Type', 'Seat comfort'\n",
    "]\n",
    "\n",
    "# Ensure all important features exist in dataframe columns\n",
    "important_features = [feat for feat in important_features if feat in df.columns]\n",
    "\n",
    "# Use only important features for X\n",
    "X = df[important_features]\n",
    "y = df['satisfaction_encoded']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79da550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression -- Accuracy: 0.8502, F1-score: 0.8316\n",
      "RandomForest -- Accuracy: 0.9420, F1-score: 0.9332\n",
      "GradientBoosting -- Accuracy: 0.9285, F1-score: 0.9185\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# If you want to apply SMOTE only on train\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Models dictionary\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to evaluate model and log with MLflow\n",
    "def train_and_log_model(model_name, model, X_train, y_train, X_test, y_test):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Log params and metrics\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"precision\", prec)\n",
    "        mlflow.log_metric(\"recall\", rec)\n",
    "        \n",
    "        # Log confusion matrix as artifact (optional: save as image or csv)\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        import os\n",
    "        \n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        \n",
    "        cm_path = f'confusion_matrix_{model_name}.png'\n",
    "        plt.savefig(cm_path)\n",
    "        plt.close()\n",
    "        \n",
    "        mlflow.log_artifact(cm_path)\n",
    "        os.remove(cm_path)\n",
    "        \n",
    "        # Log the model itself\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        \n",
    "        print(f\"{model_name} -- Accuracy: {acc:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "# Train and log all models\n",
    "for name, mdl in models.items():\n",
    "    train_and_log_model(name, mdl, X_train_smote, y_train_smote, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c71364b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression -- Accuracy: 0.8516, F1-score: 0.8330\n",
      "GradientBoosting -- Accuracy: 0.9285, F1-score: 0.9185\n",
      "RandomForest -- Accuracy: 0.9420, F1-score: 0.9332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define numeric columns to scale\n",
    "# Define numeric columns from your important features (only numeric ones)\n",
    "numeric_cols = ['Age', 'Flight Distance'] + [feat for feat in important_features if feat in rating_features]\n",
    "\n",
    "# Create scaler and fit on train data only\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# We’ll build pipelines for LR and GB that first scale numeric features\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', 'passthrough', [col for col in X.columns if col not in numeric_cols])  # categorical already encoded\n",
    "    ])\n",
    "\n",
    "\n",
    "# Pipelines\n",
    "pipelines = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=2000, random_state=42))\n",
    "    ]),\n",
    "    'GradientBoosting': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "    ]),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42)  # no scaling pipeline needed\n",
    "}\n",
    "\n",
    "# Train-test split and SMOTE as before\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train and log function adapted to handle pipeline or model directly\n",
    "def train_and_log_model(model_name, model, X_train, y_train, X_test, y_test):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"precision\", prec)\n",
    "        mlflow.log_metric(\"recall\", rec)\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        import os\n",
    "        \n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        \n",
    "        cm_path = f'confusion_matrix_{model_name}.png'\n",
    "        plt.savefig(cm_path)\n",
    "        plt.close()\n",
    "        \n",
    "        mlflow.log_artifact(cm_path)\n",
    "        os.remove(cm_path)\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        \n",
    "        print(f\"{model_name} -- Accuracy: {acc:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "# Train all models again\n",
    "for name, mdl in pipelines.items():\n",
    "    train_and_log_model(name, mdl, X_train_smote, y_train_smote, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2810b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save label encoders dict\n",
    "with open('label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "# Save scaler inside pipeline (only needed for LogisticRegression and GradientBoosting)\n",
    "# You can save entire pipeline directly:\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(pipelines['RandomForest'], f)  # or your selected model pipeline\n",
    "\n",
    "# If scaler separate, save it as well (but here scaler is inside pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ac4dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"columns.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X.columns.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6513c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "362fdce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral or dissatisfied' 'satisfied']\n"
     ]
    }
   ],
   "source": [
    "le_target = LabelEncoder()\n",
    "df['satisfaction_encoded'] = le_target.fit_transform(df['satisfaction'])\n",
    "print(le_target.classes_)  # This should print ['dissatisfied', 'satisfied']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0154f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online boarding           0.218846\n",
      "Inflight wifi service     0.163166\n",
      "Type of Travel            0.132472\n",
      "Flight Distance           0.095036\n",
      "Inflight entertainment    0.092446\n",
      "Class_Business            0.078307\n",
      "Age                       0.070241\n",
      "Ease of Online booking    0.055655\n",
      "Customer Type             0.047314\n",
      "Seat comfort              0.046516\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('best_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "feat_imp = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(feat_imp.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e8d380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      " 0    58879\n",
      "1    45025\n",
      "Name: satisfaction_encoded, dtype: int64\n",
      "After SMOTE:\n",
      " 1    47103\n",
      "0    47103\n",
      "Name: satisfaction_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original class distribution:\\n\", y.value_counts())\n",
    "print(\"After SMOTE:\\n\", pd.Series(y_train_smote).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "365cb1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Dissatisfied       0.95      0.95      0.95     11776\n",
      "   Satisfied       0.93      0.94      0.93      9005\n",
      "\n",
      "    accuracy                           0.94     20781\n",
      "   macro avg       0.94      0.94      0.94     20781\n",
      "weighted avg       0.94      0.94      0.94     20781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['Dissatisfied', 'Satisfied']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b54bb3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral or dissatisfied' 'satisfied']\n"
     ]
    }
   ],
   "source": [
    "le_target = LabelEncoder()\n",
    "df['satisfaction_encoded'] = le_target.fit_transform(df['satisfaction'])\n",
    "print(le_target.classes_)   # Must print: ['neutral or dissatisfied' 'satisfied']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2eeac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "745cd8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original distribution:\n",
      " 0    58879\n",
      "1    45025\n",
      "Name: satisfaction_encoded, dtype: int64\n",
      "Train distribution before SMOTE:\n",
      " 0    47103\n",
      "1    36020\n",
      "Name: satisfaction_encoded, dtype: int64\n",
      "Train distribution after SMOTE:\n",
      " 1    47103\n",
      "0    47103\n",
      "Name: satisfaction_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original distribution:\\n\", y.value_counts())\n",
    "print(\"Train distribution before SMOTE:\\n\", y_train.value_counts())\n",
    "print(\"Train distribution after SMOTE:\\n\", pd.Series(y_train_smote).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8f3e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution after SMOTE:\n",
      "1    47103\n",
      "0    47103\n",
      "Name: satisfaction_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_smote).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14b2f974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predicted probabilities for 'satisfied' class: [0.   0.03 0.9  0.03 0.   0.   1.   0.07 0.67 1.  ]\n"
     ]
    }
   ],
   "source": [
    "if hasattr(model, \"predict_proba\"):\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"Sample predicted probabilities for 'satisfied' class: {y_probs[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab95daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with prob > 0.5: 9045\n",
      "Total test samples: 20781\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples with prob > 0.5:\", (y_probs > 0.5).sum())\n",
    "print(\"Total test samples:\", len(y_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9bdd0b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 11736, 1: 9045})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_pred))  # y_pred from model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3f65a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "neutral or dissatisfied       0.97      0.90      0.93     11776\n",
      "              satisfied       0.88      0.96      0.92      9005\n",
      "\n",
      "               accuracy                           0.93     20781\n",
      "              macro avg       0.92      0.93      0.92     20781\n",
      "           weighted avg       0.93      0.93      0.93     20781\n",
      "\n",
      "Predicted class counts with threshold 0.3: Counter({0: 10933, 1: 9848})\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "y_pred_thresh = (y_probs >= threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_thresh, target_names=le_target.classes_))\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Predicted class counts with threshold 0.3:\", Counter(y_pred_thresh))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
